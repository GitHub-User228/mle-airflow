{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед запуском убедитесь, что в корне проекта есть файл .env и в нем заполнены выданные вам креды подключения к базам данных и хранилищу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подгружаем .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Считываем все креды\n",
    "src_host = os.environ.get('DB_SOURCE_HOST')\n",
    "src_port = os.environ.get('DB_SOURCE_PORT')\n",
    "src_username = os.environ.get('DB_SOURCE_USER')\n",
    "src_password = os.environ.get('DB_SOURCE_PASSWORD')\n",
    "src_db = os.environ.get('DB_SOURCE_NAME') \n",
    "\n",
    "dst_host = os.environ.get('DB_DESTINATION_HOST')\n",
    "dst_port = os.environ.get('DB_DESTINATION_PORT')\n",
    "dst_username = os.environ.get('DB_DESTINATION_USER')\n",
    "dst_password = os.environ.get('DB_DESTINATION_PASSWORD')\n",
    "dst_db = os.environ.get('DB_DESTINATION_NAME')\n",
    "\n",
    "s3_bucket = os.environ.get('S3_BUCKET_NAME')\n",
    "s3_access_key = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "s3_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим соединения\n",
    "src_conn = create_engine(f'postgresql://{src_username}:{src_password}@{src_host}:{src_port}/{src_db}')\n",
    "# dst_conn = create_engine(f'postgresql://{dst_username}:{dst_password}@{dst_host}:{dst_port}/{dst_db}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример выгрузки данных из БД\n",
    "TABLE = 'contracts'\n",
    "SQL = f'select * from {TABLE}'\n",
    "data = pd.read_sql(SQL, src_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А дальше, творите!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://mle_ro:HI&ykgu6tj@rc1b-uh7kdmcx67eomesf.mdb.yandexcloud.net:6432/playground_common'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'postgresql://{src_username}:{src_password}@{src_host}:{src_port}/{src_db}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = create_engine(f'postgresql://{src_username}:{src_password}@{src_host}:{src_port}/{src_db}')\n",
    "\n",
    "\n",
    "def extract(cnx) -> pd.DataFrame:\n",
    "  # сначала напишите SQL-запрос, который объединяет все таблицы в одну\n",
    "\tsql_query = f\"\"\"\n",
    "\tSELECT * FROM contracts c\n",
    "\tLEFT JOIN internet USING (customer_id)\n",
    "\tLEFT JOIN personal USING (customer_id)\n",
    "\tLEFT JOIN phone USING (customer_id);\n",
    "\t\"\"\"\n",
    "\tdata = pd.read_sql(sql_query, cnx) #исполним написанный запрос\n",
    "\tdata = data.drop('index', axis=1)\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract(cnx=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data: pd.DataFrame) -> pd.DataFrame:\n",
    "\ttransformed_data = data.copy()\n",
    "\ttransformed_data['end_date'] = transformed_data['end_date'].replace({'No': None})\n",
    "\ttransformed_data['is_target'] = transformed_data['end_date'].apply(lambda x: 1 if x is not None else 0)\n",
    "\treturn transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_date</th>\n",
       "      <th>is_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7038</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7039</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7040</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7041</th>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7043 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 end_date  is_target\n",
       "0                    None          0\n",
       "1                    None          0\n",
       "2     2019-12-01 00:00:00          1\n",
       "3                    None          0\n",
       "4     2019-11-01 00:00:00          1\n",
       "...                   ...        ...\n",
       "7038                 None          0\n",
       "7039                 None          0\n",
       "7040                 None          0\n",
       "7041  2019-11-01 00:00:00          1\n",
       "7042                 None          0\n",
       "\n",
       "[7043 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# замените user, password, host, port, database_name реальными учётными данными для доступа к персональной базе данных\n",
    "conn = create_engine(f'postgresql://{dst_username}:{dst_password}@{dst_host}:{dst_port}/{dst_db}')\n",
    "\n",
    "def load(data: pd.DataFrame, db_conn: sqlalchemy.engine.base.Engine, table_name: str = 'users_churn'):\n",
    "\tdata.to_sql(name=table_name, con=db_conn, if_exists='fail', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pendulum # библиотека для работы с временем\n",
    "\n",
    "from airflow.decorators import dag # импортируем декоратор, превращающий функцию в DAG\n",
    "\n",
    "@dag(\n",
    "    schedule=\"@weekly\", # расписание\n",
    "    start_date=pendulum.datetime(2023, 12, 19, 9, tz=\"UTC\"),\n",
    "    tags=[\"new_product\"]\n",
    ")\n",
    "def run_etl_pipeline():\n",
    "    # код DAG #\n",
    "    pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DAG: run_etl_pipeline>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_etl_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = PostgresHook('destination_db')\n",
    "\n",
    "@task()\n",
    "def load(data: pd.DataFrame):\n",
    "    hook.insert_rows(\n",
    "            table=\"users_churn\",\n",
    "            replace=True,\n",
    "            target_fields=data.columns.tolist(),\n",
    "            replace_index=['customer_id'],\n",
    "            rows=data.values.tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.decorators import task\n",
    "\n",
    "hook = PostgresHook('source_db')\n",
    "\n",
    "@task()\n",
    "def extract() -> pd.DataFrame:\n",
    "\tsql_query = f\"\"\"\n",
    "        select\n",
    "            c.customer_id, c.begin_date, c.end_date, c.type, c.paperless_billing, c.payment_method, c.monthly_charges, c.total_charges,\n",
    "            i.internet_service, i.online_security, i.online_backup, i.device_protection, i.tech_support, i.streaming_tv, i.streaming_movies,\n",
    "            p.gender, p.senior_citizen, p.partner, p.dependents,\n",
    "            ph.multiple_lines\n",
    "        from contracts as c\n",
    "        left join internet as i on i.customer_id = c.customer_id\n",
    "        left join personal as p on p.customer_id = c.customer_id\n",
    "        left join phone as ph on ph.customer_id = c.customer_id\n",
    "\t\"\"\"\n",
    "\n",
    "\tconn = hook.get_conn()\n",
    "\tdata = pd.read_sql(sql_query, con=conn)\n",
    "\tconn.close()\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pendulum\n",
    "import pandas as pd\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.decorators import task, dag\n",
    "\n",
    "\n",
    "@dag(schedule='@once',\n",
    "     start_date=pendulum.datetime(2024, 1, 1, tz=\"UTC\"),\n",
    "     tags=[\"churn\"])\n",
    "def prepare_churn_dataset():\n",
    "\t\n",
    "     @task()\n",
    "     def extract() -> pd.DataFrame:\n",
    "          sql = f\"\"\"\n",
    "          select\n",
    "               c.customer_id, c.begin_date, c.end_date, c.type, c.paperless_billing, c.payment_method, c.monthly_charges, c.total_charges,\n",
    "               i.internet_service, i.online_security, i.online_backup, i.device_protection, i.tech_support, i.streaming_tv, i.streaming_movies,\n",
    "               p.gender, p.senior_citizen, p.partner, p.dependents,\n",
    "               ph.multiple_lines\n",
    "          from contracts as c\n",
    "          left join internet as i on i.customer_id = c.customer_id\n",
    "          left join personal as p on p.customer_id = c.customer_id\n",
    "          left join phone as ph on ph.customer_id = c.customer_id\n",
    "          \"\"\"\n",
    "          hook_src = PostgresHook('source_db')\n",
    "          conn = hook_src.get_conn()\n",
    "          data = pd.read_sql(sql, con=conn)\n",
    "          conn.close()\n",
    "          return data\n",
    "     \n",
    "     @task()\n",
    "     def transform(data: pd.DataFrame) -> pd.DataFrame:\n",
    "          data['target'] = (data['end_date'] != 'No').astype(int)\n",
    "          data['end_date'].replace({'No': None}, inplace=True)\n",
    "          return data \n",
    "     \n",
    "     \n",
    "     @task()\n",
    "     def load(data: pd.DataFrame):\n",
    "          hook_dst = PostgresHook('destination_db')\n",
    "          hook_dst.insert_rows(\n",
    "               table=\"users_churn\",\n",
    "               replace=True,\n",
    "               target_fields=data.columns.tolist(),\n",
    "               replace_index=['customer_id'],\n",
    "               rows=data.values.tolist()\n",
    "          )    \n",
    "\n",
    "     data = extract()\n",
    "     data = transform(data)\n",
    "     load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DAG: prepare_churn_dataset>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_churn_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Table, MetaData, Column, Integer, String, DateTime, UniqueConstraint\n",
    "\n",
    "metadata = MetaData()\n",
    "salaries_table = Table(\n",
    "    'salaries',\n",
    "    metadata,\n",
    "    Column('id', Integer, primary_key=True, autoincrement=True),\n",
    "    Column('surname', String),\n",
    "    Column('salary', Integer),\n",
    "    UniqueConstraint('surname', name='unique_employee_constraint')\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table('salaries', MetaData(), Column('id', Integer(), table=<salaries>, primary_key=True, nullable=False), Column('surname', String(), table=<salaries>), Column('salary', Integer(), table=<salaries>), schema=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/tmp/ipykernel_50685/3542497842.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> DeprecationWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: The `airflow.hooks.postgres_hook.PostgresHook` class is deprecated. Please use `</span><span style=\"color: #808000; text-decoration-color: #808000\">'airflow.providers.postgres.hooks.postgres.PostgresHook'</span><span style=\"color: #808000; text-decoration-color: #808000\">`.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/tmp/ipykernel_50685/\u001b[0m\u001b[1;33m3542497842.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m2\u001b[0m\u001b[1;33m DeprecationWarning\u001b[0m\u001b[33m: The `airflow.hooks.postgres_hook.PostgresHook` class is deprecated. Please use `\u001b[0m\u001b[33m'airflow.providers.postgres.hooks.postgres.PostgresHook'\u001b[0m\u001b[33m`.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-08-16T12:08:48.825+0000\u001b[0m] {\u001b[34mconnection.py:\u001b[0m471} ERROR\u001b[0m - Unable to retrieve connection from secrets backend (MetastoreBackend). Checking subsequent secrets backend.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1910, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 736, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlite3.OperationalError: no such table: connection\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/airflow/models/connection.py\", line 466, in get_connection_from_secrets\n",
      "    conn = secrets_backend.get_connection(conn_id=conn_id)\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/airflow/utils/session.py\", line 79, in wrapper\n",
      "    return func(*args, session=session, **kwargs)\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/airflow/secrets/metastore.py\", line 42, in get_connection\n",
      "    conn = session.scalar(select(Connection).where(Connection.conn_id == conn_id).limit(1))\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 1747, in scalar\n",
      "    return self.execute(\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/orm/session.py\", line 1717, in execute\n",
      "    result = conn._execute_20(statement, params or {}, execution_options)\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1710, in _execute_20\n",
      "    return meth(self, args_10style, kwargs_10style, execution_options)\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/sql/elements.py\", line 334, in _execute_on_connection\n",
      "    return connection._execute_clauseelement(\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1577, in _execute_clauseelement\n",
      "    ret = self._execute_context(\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1953, in _execute_context\n",
      "    self._handle_dbapi_exception(\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 2134, in _handle_dbapi_exception\n",
      "    util.raise_(\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/util/compat.py\", line 211, in raise_\n",
      "    raise exception\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/base.py\", line 1910, in _execute_context\n",
      "    self.dialect.do_execute(\n",
      "  File \"/home/mle-user/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/sqlalchemy/engine/default.py\", line 736, in do_execute\n",
      "    cursor.execute(statement, parameters)\n",
      "sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) no such table: connection\n",
      "[SQL: SELECT connection.password, connection.extra, connection.id, connection.conn_id, connection.conn_type, connection.description, connection.host, connection.schema, connection.login, connection.port, connection.is_encrypted, connection.is_extra_encrypted \n",
      "FROM connection \n",
      "WHERE connection.conn_id = ?\n",
      " LIMIT ? OFFSET ?]\n",
      "[parameters: ('destination_db', 1, 0)]\n",
      "(Background on this error at: https://sqlalche.me/e/14/e3q8)\n"
     ]
    },
    {
     "ename": "AirflowNotFoundException",
     "evalue": "The conn_id `destination_db` isn't defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAirflowNotFoundException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mairflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpostgres_hook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PostgresHook\n\u001b[1;32m      4\u001b[0m hook \u001b[38;5;241m=\u001b[39m PostgresHook(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdestination_db\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m database_connection \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect(database_connection)\u001b[38;5;241m.\u001b[39mhas_table(salaries_table\u001b[38;5;241m.\u001b[39mname): \n\u001b[1;32m      9\u001b[0m     metadata\u001b[38;5;241m.\u001b[39mcreate_all(database_connection) \n",
      "File \u001b[0;32m~/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/airflow/providers/postgres/hooks/postgres.py:128\u001b[0m, in \u001b[0;36mPostgresHook.get_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establishes a connection to a postgres database.\"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m conn_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn_name_attr)\n\u001b[0;32m--> 128\u001b[0m conn \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn_id\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# check for authentication via AWS IAM\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mextra_dejson\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miam\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/airflow/hooks/base.py:72\u001b[0m, in \u001b[0;36mBaseHook.get_connection\u001b[0;34m(cls, conn_id)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03mGet connection, given connection id.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m:param conn_id: connection id\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m:return: connection\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mairflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconnection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Connection\n\u001b[0;32m---> 72\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mConnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection_from_secrets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing connection ID \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for task execution.\u001b[39m\u001b[38;5;124m\"\u001b[39m, conn\u001b[38;5;241m.\u001b[39mconn_id)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "File \u001b[0;32m~/mle_projects/mle-airflow/.venv_project_name/lib/python3.10/site-packages/airflow/models/connection.py:477\u001b[0m, in \u001b[0;36mConnection.get_connection_from_secrets\u001b[0;34m(cls, conn_id)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m         log\u001b[38;5;241m.\u001b[39mexception(\n\u001b[1;32m    472\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to retrieve connection from secrets backend (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChecking subsequent secrets backend.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    474\u001b[0m             \u001b[38;5;28mtype\u001b[39m(secrets_backend)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    475\u001b[0m         )\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m AirflowNotFoundException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe conn_id `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconn_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt defined\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAirflowNotFoundException\u001b[0m: The conn_id `destination_db` isn't defined"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "from airflow.hooks.postgres_hook import PostgresHook\n",
    "\n",
    "hook = PostgresHook(\"destination_db\")\n",
    "database_connection = hook.get_conn()\n",
    "\n",
    "\n",
    "if not inspect(database_connection).has_table(salaries_table.name): \n",
    "    metadata.create_all(database_connection) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_mle_sprint1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
